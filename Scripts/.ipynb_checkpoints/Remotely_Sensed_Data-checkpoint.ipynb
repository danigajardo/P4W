{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "derived-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import ee\n",
    "import geemap\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import qgrid\n",
    "# from osgeo import gdal\n",
    "# from osgeo import osr\n",
    "# import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-howard",
   "metadata": {},
   "source": [
    "# Input locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "therapeutic-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r'C:\\Users\\samantha.kuzma\\OneDrive - World Resources Institute'\n",
    "\n",
    "# - - - FOLDERS - - -  - - -  - - - #\n",
    "# ReservoirWatch/ Power4Water\n",
    "data_root = os.path.join(root, \"ReservoirWatch\", \"Data\") # main data folder\n",
    "# Untouched copies of raw data\n",
    "raw_path = os.path.join(data_root, \"Raw\") # Raw folder\n",
    "cwc_path = os.path.join(raw_path, \"CWC\") # CWC reservoir levels 2000 through Jan 2021\n",
    "# Processed data used in analysis \n",
    "analysis_path = os.path.join(data_root, \"Analysis\") # Analysis folder\n",
    "rs_path = os.path.join(analysis_path, \"RemotelySensed\")\n",
    "context_gdb = os.path.join(analysis_path, \"contextual.gdb\") # Locally saved spatial data\n",
    "res_ids_path = os.path.join(analysis_path, \"reservoir_to_IDs_lookup.csv\")# Matches each reservoir to basins (containing, upstream, downstream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-smart",
   "metadata": {},
   "source": [
    "GEE Documentation\n",
    "https://tutorials.geemap.org/Analysis/zonal_statistics/\n",
    "\n",
    "Example using CHIRPS Pentad data\n",
    "https://spatialthoughts.com/2020/10/28/rainfall-data-gee/\n",
    "\n",
    "Help understanding Scale\n",
    "https://developers.google.com/earth-engine/guides/scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prescribed-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()\n",
    "\n",
    "def remotely_sensed_time_series(rs_collection, ts_start, ts_end, ts_delta, ic_reducer, zs_reducer, zs_boundary, zs_scale):\n",
    "    '''    \n",
    "    rs_collection = Remotely Sensed image collection on Google Earth Engine (rs = remotely sensed)\n",
    "    ts_start = Time series start date (must be datetime format) (ts = time series)\n",
    "    ts_end = Times series end date (must be datetime)\n",
    "    ts_delta = Increment between time steps \n",
    "        ->[day, month, year]\n",
    "    ic_reducer = How to summarize multiple timesteps into 1 image (ic = Image collection)\n",
    "        ->[sum, mean, min, max]\n",
    "    zs_reducer = How to summarize image by boundary (zs = zonal statistics)\n",
    "        ->[MEAN, MAXIMUM, MINIMUM, MEDIAN, STD, MIN_MAX, VARIANCE, SUM]\n",
    "    zs_boundary = shapes used to summarizes raster data. ex: Hydrobasin 6 watersheds\n",
    "    zs_scale = Scale\n",
    "    '''\n",
    "    # DICTIONARIES\n",
    "    # Dictionary to create incremental space between time steps\n",
    "    ts_delta_DICT = {\"day\": datetime.timedelta(days=1) , \n",
    "                     \"month\": relativedelta(months = 1) , \n",
    "                     \"year\": relativedelta(years = 1) }\n",
    "    # Dictionary to select method to reduce image collection to 1 image\n",
    "    ic_reducer_dict = {\"sum\": ee.Reducer.sum(), \"mean\": ee.Reducer.mean(), \n",
    "                       \"min\": ee.Reducer.min(), \"max\": ee.Reducer.max()}\n",
    "    \n",
    "    # Select from dictionaries\n",
    "    icr = ic_reducer_dict.get(ic_reducer) # Find reducer\n",
    "    tsd = ts_delta_DICT.get(ts_delta)\n",
    "    # Create copy of timeseries start date that won't change\n",
    "    og_ts_start = ts_start\n",
    "    \n",
    "    # Loop through dates in timeseries (ts_start will update with each iteration)\n",
    "    while ts_start <= ts_end:\n",
    "        print(ts_start)\n",
    "        \n",
    "        # 1. Turn start date into GEE date\n",
    "        gee_startDate = ee.Date.fromYMD(ts_start.year, ts_start.month, ts_start.day)\n",
    "        gee_endDate = gee_startDate.advance(1, ts_delta) # Create end date for GEE range\n",
    "        # 2. Read in remotely sensed data (filter by date), turn into 1 image\n",
    "        rs_image = ee.ImageCollection(rs_collection).filter(ee.Filter.date(gee_startDate, gee_endDate))\n",
    "        \n",
    "        rs_reduced = rs_image.reduce(icr) # Reduce image\n",
    "        \n",
    "        # 3. Run zonal statistics (automatically download)\n",
    "        geemap.zonal_statistics(rs_reduced, zs_boundary, \"rs_download_temp.csv\", statistics_type= zs_reducer, scale = zs_scale)\n",
    "        \n",
    "        # 4. Read downloaded results back in\n",
    "        stats = pd.read_csv(\"rs_download_temp.csv\", header = 0, index_col = 4)\n",
    "        stats = stats.filter([zs_reducer.lower()])\n",
    "        stats['date'] = ts_start\n",
    "        \n",
    "        # 5. Aggregate data together through each loop\n",
    "        # If it's the the start of the loop...\n",
    "        if og_ts_start == ts_start:\n",
    "            df_final = stats.copy()\n",
    "        #...if not, append onto dataframe\n",
    "        else:\n",
    "            df_final = df_final.append(stats)\n",
    "       \n",
    "        # 6. Move ts_start to next step\n",
    "        ts_start = ts_start + tsd\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(datetime.date(2020, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sophisticated-folks",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ee' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a695c0b24b2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# GEE Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mbasins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mee\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFeatureCollection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'projects/WRI-Aquaduct/Power4Water/P4W_hy6'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mchirps_daily\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"UCSB-CHG/CHIRPS/DAILY\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ee' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "outFormat = \"{:s}_TS-{:s}_{:s}_STEP-{:s}_IC-{:s}_ZS-{:s}_Scale-{:s}.csv\".format\n",
    "\n",
    "# GEE Data\n",
    "basins = ee.FeatureCollection(r'projects/WRI-Aquaduct/Power4Water/P4W_hy6')\n",
    "chirps_daily = \"UCSB-CHG/CHIRPS/DAILY\"\n",
    "\n",
    "\n",
    "# Set inputs\n",
    "timeseries_start = datetime.date(2000, 1, 1)\n",
    "timeseries_end = datetime.date(2020, 12, 31)\n",
    "timeseries_step = 'month'\n",
    "temporal_reducer = 'sum'\n",
    "spatial_reducer = 'MEAN'\n",
    "scale = 5000\n",
    "\n",
    "# Summarize remotely sensed data\n",
    "df_chirps = remotely_sensed_time_series(rs_collection = chirps_daily, \n",
    "                                        ts_start = timeseries_start, \n",
    "                                        ts_end = timeseries_end, \n",
    "                                        ts_delta = timeseries_step, \n",
    "                                        ic_reducer = temporal_reducer, \n",
    "                                        zs_reducer = spatial_reducer, \n",
    "                                        zs_boundary = basins, \n",
    "                                        zs_scale = scale)\n",
    "\n",
    "outpath = os.path.join(rs_path, outFormat(\"chirps_daily\", str(timeseries_start), str(timeseries_end), timeseries_step,\n",
    "                                          temporal_reducer, spatial_reducer, str(scale)))\n",
    "\n",
    "df_chirps.reset_index().sort_values(['PFAF_ID', 'date']).to_csv(outpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "outFormat = \"{:s}_TS-{:s}_{:s}_STEP-{:s}_IC-{:s}_ZS-{:s}_Scale-{:s}.csv\".format\n",
    "\n",
    "# Set inputs\n",
    "timeseries_start = datetime.date(2020, 1, 1)\n",
    "timeseries_end = datetime.date(2020, 12, 31)\n",
    "timeseries_step = 'day'\n",
    "temporal_reducer = 'sum'\n",
    "spatial_reducer = 'MEAN'\n",
    "scale = 5000\n",
    "\n",
    "\n",
    "outpath = os.path.join(rs_path, outFormat(\"chirps_daily\", str(timeseries_start), str(timeseries_end), timeseries_step,\n",
    "                                          temporal_reducer, spatial_reducer, str(scale)))\n",
    "\n",
    "df_chirps.reset_index().sort_values(['PFAF_ID', 'date']).to_csv(outpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "'{}.csv'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid.show_grid(df_chirps.sort_values(['PFAF_ID', 'date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()\n",
    "rs_collection = chirps_daily \n",
    "ts_start = datetime.date(2018, 1, 1)\n",
    "ts_end = datetime.date(2020, 12, 31)\n",
    "ts_delta =\"day\"\n",
    "ic_reducer = \"sum\"\n",
    "zs_reducer = \"MEAN\"\n",
    "zs_boundary = basins\n",
    "zs_scale = 5000\n",
    "\n",
    "# DICTIONARIES\n",
    "# Dictionary to create incremental space between time steps\n",
    "ts_delta_DICT = {\"day\": datetime.timedelta(days=1) , \n",
    "                 \"month\": relativedelta(months = 1) , \n",
    "                 \"year\": relativedelta(years = 1) }\n",
    "# Dictionary to select method to reduce image collection to 1 image\n",
    "ic_reducer_dict = {\"sum\": ee.Reducer.sum(), \"mean\": ee.Reducer.mean(), \n",
    "                   \"min\": ee.Reducer.min(), \"max\": ee.Reducer.max()}\n",
    "\n",
    "# Select from dictionaries\n",
    "icr = ic_reducer_dict.get(ic_reducer) # Find reducer\n",
    "tsd = ts_delta_DICT.get(ts_delta)\n",
    "# Create copy of timeseries start date that won't change\n",
    "og_ts_start = ts_start\n",
    "\n",
    "# Loop through dates in timeseries (ts_start will update with each iteration)\n",
    "while ts_start <= ts_end:\n",
    "    print(ts_start)\n",
    "\n",
    "    # 1. Turn start date into GEE date\n",
    "    gee_startDate = ee.Date.fromYMD(ts_start.year, ts_start.month, ts_start.day)\n",
    "    gee_endDate = gee_startDate.advance(1, ts_delta) # Create end date for GEE range\n",
    "    # 2. Read in remotely sensed data (filter by date), turn into 1 image\n",
    "    rs_image = ee.ImageCollection(rs_collection).filter(ee.Filter.date(gee_startDate, gee_endDate))\n",
    "\n",
    "    rs_reduced = rs_image.reduce(icr) # Reduce image\n",
    "\n",
    "    # 3. Run zonal statistics (automatically download)\n",
    "    geemap.zonal_statistics(rs_reduced, zs_boundary, \"rs_download_temp.csv\", statistics_type= zs_reducer, scale = zs_scale)\n",
    "\n",
    "    # 4. Read downloaded results back in\n",
    "    stats = pd.read_csv(\"rs_download_temp.csv\", header = 0, index_col = 4)\n",
    "    stats = stats.filter([zs_reducer.lower()])\n",
    "    stats['date'] = ts_start\n",
    "\n",
    "    # 5. Aggregate data together through each loop\n",
    "    # If it's the the start of the loop...\n",
    "    if og_ts_start == ts_start:\n",
    "        df_final = stats.copy()\n",
    "    #...if not, append onto dataframe\n",
    "    else:\n",
    "        df_final = df_final.append(stats)\n",
    "\n",
    "    # 6. Move ts_start to next step\n",
    "    ts_start = ts_start + tsd\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.reset_index().sort_values(['PFAF_ID', 'date'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
