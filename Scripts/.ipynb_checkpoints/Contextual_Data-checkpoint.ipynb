{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "exempt-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.8 (Kuzma's env: py_38)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from itertools import chain\n",
    "import qgrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-browser",
   "metadata": {},
   "source": [
    "# Input Locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "opposed-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r'C:\\Users\\samantha.kuzma\\OneDrive - World Resources Institute'\n",
    "\n",
    "# - - - FOLDERS - - -  - - -  - - - #\n",
    "# ReservoirWatch specific\n",
    "data_root = os.path.join(root, \"ReservoirWatch\", \"Data\")\n",
    "raw_path = os.path.join(data_root, \"Raw\")\n",
    "analysis_path = os.path.join(data_root, \"Analysis\")\n",
    "\n",
    "context_gdb = os.path.join(analysis_path, \"contextual.gdb\")\n",
    "cwc_path = os.path.join(raw_path, \"CWC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-replica",
   "metadata": {},
   "source": [
    "# Output Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "nonprofit-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This file matches each Reservoir to its GRnD ID, CWC Name, State ID,\n",
    "Hydrobasin 6 basins (contain reservoir, upstream, and downstream), and\n",
    "FAO Major and Sub basins (contain reservoir, upstream, and downstream),\n",
    "'''\n",
    "res_ids_path = os.path.join(analysis_path, \"reservoir_to_IDs_lookup.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-stationery",
   "metadata": {},
   "source": [
    "# Match reservoirs to spatial boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-performer",
   "metadata": {},
   "source": [
    "### Read in spatial data (saved in Geodatabase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "green-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in \n",
    "res = gpd.read_file(context_gdb, layer='Reservoir')\n",
    "# hy6 = gpd.read_file(context_gdb, layer='IND_aq30')\n",
    "hy6 = gpd.read_file(context_gdb, layer='IND_hy6_wri')\n",
    "ad2 = gpd.read_file(context_gdb, layer='IND_adm2_gadm36')\n",
    "# fao = gpd.read_file(context_gdb, layer='IND_majbas_fao') # Excludes some downstream watersheds, can't use\n",
    "fao = gpd.read_file(context_gdb, layer='ALL_majbas_fao') # Global FAO named basins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-horizon",
   "metadata": {},
   "source": [
    "### Match CWC names to reservoir shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "convenient-netherlands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRaND unmatched_names [' ', 'Indirasagar', 'Panchet Hill', 'Sriram Sagar']\n",
      "CWC unmatched_names ['Panchet', 'Pench', 'Sriramsagar', 'indirasagar']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-159-2b3974f0b115>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res_lookup['CWC_NAME'][~res_lookup['DAM_NAME'].isin(unmatched_names)] = res['DAM_NAME'] # Add names that match\n"
     ]
    }
   ],
   "source": [
    "# Match CWC data to shapefile/GRaND Reservoir IDs\n",
    "res_lookup = res.filter(['GRAND_ID', 'DAM_NAME', 'RIVER', 'MAIN_BASIN'])\n",
    "# Reservoir names\n",
    "res_names = os.listdir(cwc_path) # CWC Reservoir Names\n",
    "GRaND_names = res_lookup['DAM_NAME'].tolist() # GRaND Names (in shapefile)\n",
    "# Find names that don't match\n",
    "unmatched_names = sorted([x for x in GRaND_names if x not in res_names])\n",
    "cwc_unmatched_names = sorted([x for x in res_names if x not in GRaND_names])\n",
    "print(\"GRaND unmatched_names\", unmatched_names)\n",
    "print(\"CWC unmatched_names\", cwc_unmatched_names)\n",
    "# Create CWC Name column in shapefile\n",
    "res_lookup['CWC_NAME'] = np.nan\n",
    "# Add names that do match\n",
    "res_lookup['CWC_NAME'][~res_lookup['DAM_NAME'].isin(unmatched_names)] = res['DAM_NAME'] # Add names that match\n",
    "# Manually add the rest\n",
    "res_lookup['CWC_NAME'][res_lookup['DAM_NAME']==' '] = 'Pench'\n",
    "res_lookup['CWC_NAME'][res_lookup['DAM_NAME']=='Indirasagar'] = 'indirasagar'\n",
    "res_lookup['CWC_NAME'][res_lookup['DAM_NAME']=='Panchet Hill'] = 'Panchet'\n",
    "res_lookup['CWC_NAME'][res_lookup['DAM_NAME']=='Sriram Sagar'] = 'Sriramsagar'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-copyright",
   "metadata": {},
   "source": [
    "### Match CWC names to Hydrobasin 6, States, and FAO Basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "optional-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to join reservoir shapefile to other geographical boundaries\n",
    "def find_intersecting_ids(shape, shape_id):\n",
    "    joined = gpd.sjoin(res, shape, how=\"left\", op='intersects') # Join shapefile to reservoir shapefile\n",
    "    list_ids = joined.groupby(['GRAND_ID'])[shape_id].agg(list).to_frame() # create a list of all IDs that intersect with reservoir\n",
    "    list_ids[shape_id].apply(lambda x: list(set(x))) # Remove unique IDs\n",
    "    return list_ids[shape_id]\n",
    "\n",
    "# Create dataframe\n",
    "res_ids = res_lookup.filter(['GRAND_ID', 'CWC_NAME']).set_index(['GRAND_ID'])\n",
    "res_ids['PFAF_ID'] = find_intersecting_ids(hy6, 'PFAF_ID')\n",
    "res_ids['HYBAS_ID'] = find_intersecting_ids(hy6, 'HYBAS_ID')\n",
    "res_ids['GID_2'] = find_intersecting_ids(ad2, 'GID_2')\n",
    "res_ids['MAJ_BAS'] = find_intersecting_ids(fao, 'MAJ_BAS')\n",
    "res_ids['SUB_BAS'] = find_intersecting_ids(fao, 'SUB_BAS')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-parameter",
   "metadata": {},
   "source": [
    "# Find Upstream and Downstream basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "southwest-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUnction to ID upstream and downstream watersheds per basin\n",
    "def basin_upstream_downstream(within_basins, lookp_basins, bas_ID, bas_DOWNSTREAM):\n",
    "    # within_basins = list of basins that contain reservoirs\n",
    "    # lookup_basins = original watershed data that links basins to their downstream basins\n",
    "    # bas_ID = Uniqe basin ID used in original watershed data\n",
    "    # bas_DOWNSTREAM = Field name used in original watershed data to list downstream basin\n",
    "    \n",
    "    # # Create dictionary to hold results of upstrea/downstream\n",
    "    hyDict = {key: [] for key in within_basins} \n",
    "    # # Loop through every sub basin that contains reservoir\n",
    "    for bas in within_basins:\n",
    "#         print(bas)\n",
    "    # - - - - - - - - - - - UPSTREAM - - - - - - - - - # \n",
    "#         print('Start Upstream')\n",
    "        upstreams = [] # list to hold all upstream basins for selected sub_basin\n",
    "        # 1st round, find all basins which flow to selected subbasins. IE upstream basinss\n",
    "        ups = list(set(lookp_basins[bas_ID][lookp_basins[bas_DOWNSTREAM] == bas].tolist())) \n",
    "    #     # As long as new upstream basins are found, keep running the script\n",
    "        while len(ups) > 0:\n",
    "            # for every upstream basin in list, find it's upstream basins\n",
    "            for up in ups:\n",
    "                # First, add selected upstream basin to list of upstream basins\n",
    "                upstreams.append(int(up)) # Add basin to list of upstream basins\n",
    "                # Now find which basins are upstream of it\n",
    "                ups_up = list(set(lookp_basins[bas_ID][lookp_basins[bas_DOWNSTREAM] == int(up)].tolist()))\n",
    "                # Add those basins to the looping list of upstream basins\n",
    "                ups = ups + ups_up\n",
    "                # Remove the current selected upstream basin from looping list\n",
    "                ups.remove(up)\n",
    "                # Repeat For loop until no more upstream basins are found\n",
    "        # Remove duplicates from upstream list\n",
    "        upstreams = list(set(upstreams))  \n",
    "        # Add to dictionary\n",
    "        hyDict[bas].append(upstreams)\n",
    "    # - - - - - - - - - - - DOWNSTREAM - - - - - - - - - #    \n",
    "    #     # Find all downstream basins\n",
    "#         print('Start Downstream')\n",
    "        downstreams = [] # list to hold all downstream basins for selected sub_basin\n",
    "        # 1st round, find all basins the selected subbasin flows to. IE downstream basins\n",
    "        downs = list(set(lookp_basins[bas_DOWNSTREAM][lookp_basins[bas_ID] == bas].tolist())) \n",
    "        # Check to see if downstream exists\n",
    "        if downs[0] == 0:\n",
    "            print('check:', len(downs))\n",
    "            downs = []\n",
    "        # As long as new downstream basins are found, keep running the script\n",
    "        while len(downs) > 0:\n",
    "            # for every downstream basin in list, find it's downstream basins\n",
    "            for down in downs:\n",
    "                downstreams.append(int(down)) # Add basin to list of downstream basins\n",
    "                # Now find which basins are downstream of it\n",
    "                downs_down = list(set(lookp_basins[bas_DOWNSTREAM][lookp_basins[bas_ID] == down].tolist())) \n",
    "                # Add those basins to the looping list of downstream basins\n",
    "                downs = downs + downs_down\n",
    "                # Remove the current selected downstream basin from looping list\n",
    "                downs.remove(down)\n",
    "                # Repeat For loop until no more downstream basins are found\n",
    "        # Remove duplicates from upstream list\n",
    "        downstreams = list(set(downstreams))\n",
    "        # Add to dictionary\n",
    "        hyDict[bas].append(downstreams)\n",
    "\n",
    "    # Turn results into dataframe\n",
    "    df_hydro = pd.DataFrame.from_dict(hyDict).transpose()\n",
    "    df_hydro.rename(columns = {0: \"Upstream\", 1: \"Downstream\"}, inplace = True)\n",
    "    return df_hydro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-evening",
   "metadata": {},
   "source": [
    "## Find upstream and downstream basins for every basin that holds a reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "cross-myrtle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check: 1\n"
     ]
    }
   ],
   "source": [
    "# - - - - - - SET UP INPUTS - - - - - - #\n",
    "# HYDROBASIN 6 (smaller watersheds, match Aqueduct data)\n",
    "# List of all hybas6 basins that the P4Water reservoirs lie in \n",
    "all_hy6_bas = sorted(list(set(chain.from_iterable(res_ids.HYBAS_ID.tolist()))))\n",
    "all_hy6_bas = [int(x) for x in all_hy6_bas] # Make sure they are integers not floats\n",
    "\n",
    "# FAO SUB BASINS (larger basins, named)\n",
    "# Focusing on the FAO basins for now to match reservoirs to upstream and downstream basins\n",
    "# List of all maj basins that the P4Water reservoirs lie in \n",
    "all_maj_bas = sorted(list(set(chain.from_iterable(res_ids.MAJ_BAS.tolist()))))\n",
    "# List of all sub basins that the P4Water reservoirs lie in \n",
    "all_sub_bas = sorted(list(set(chain.from_iterable(res_ids.SUB_BAS.tolist()))))\n",
    "# Filter FAO data by P4W's major basins (not all subbas IDs are unique)\n",
    "fao_p4w = fao[fao.MAJ_BAS.isin(all_maj_bas)]\n",
    "\n",
    "# - - - - - - FIND HYDRO CONNECTIONS - - - - - - #\n",
    "# Find upstream and downstream basins for every basin that contains a reservoir\n",
    "df_hy6_hydro = basin_upstream_downstream(all_hy6_bas, hy6, \"HYBAS_ID\", \"NEXT_DOWN\")\n",
    "df_fao_hydro = basin_upstream_downstream(all_sub_bas, fao_p4w, \"SUB_BAS\", \"TO_BAS\")\n",
    "\n",
    "# - - - - - - CLEAN DATA - - - - - - #\n",
    "# Clean up data.\n",
    "# FAO: Remove non-basins (-999) from downstream lists\n",
    "df_fao_hydro['Downstream'] = df_fao_hydro['Downstream'].apply(lambda x: [i for i in x if i != -999])\n",
    "\n",
    "# Hybas6: convert HYBAS_ID to pFAF_IDs\n",
    "df_pf6_hydro = df_hy6_hydro.reset_index()\n",
    "df_pf6_hydro['Upstream'] = df_pf6_hydro['Upstream'].apply(lambda x: hy6.PFAF_ID[hy6.HYBAS_ID.isin(x)].tolist())\n",
    "df_pf6_hydro['Downstream'] = df_pf6_hydro['Downstream'].apply(lambda x: hy6.PFAF_ID[hy6.HYBAS_ID.isin(x)].tolist())\n",
    "df_pf6_hydro['index'] = df_pf6_hydro['index'].apply(lambda x: hy6.PFAF_ID[hy6.HYBAS_ID == x].values[0])\n",
    "df_pf6_hydro.set_index(['index'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "mediterranean-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to match reservoirs to upstream and downstream basins\n",
    "def reservoir_upstream_downstream(with_bas, hydro, hydro_type):\n",
    "    # Create blank lists to hold up and down stream basins\n",
    "    hydro_connections = []\n",
    "    # For every subbasin containing the reservoir:\n",
    "    for w in with_bas:\n",
    "        # FInd its corresponding upstream and downstream basins\n",
    "        hydro_connections.append(hydro.loc[w, hydro_type])\n",
    "      \n",
    "    # Once all up / down stream basins are found, clean up list (unnest, remove duplicates)\n",
    "    hydro_clean = sorted(list(set(chain.from_iterable(hydro_connections))))\n",
    "    return hydro_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "sealed-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns to hold upstream and downstream basins per watershed type\n",
    "res_ids['PFAF_UP'] = np.nan # Hydrobasin 6\n",
    "res_ids['PFAF_DN'] = np.nan # Hydrobasin 6\n",
    "res_ids['SUB_UP'] = np.nan # FAO\n",
    "res_ids['SUB_DN'] = np.nan # FAO\n",
    "\n",
    "# Reservoirs to PFAFIDs\n",
    "res_ids['PFAF_UP'] = res_ids['PFAF_ID'].apply(lambda x: reservoir_upstream_downstream(x, df_pf6_hydro, 'Upstream'))\n",
    "res_ids['PFAF_DN'] = res_ids['PFAF_ID'].apply(lambda x: reservoir_upstream_downstream(x, df_pf6_hydro, 'Downstream'))\n",
    "# Reservoirs to FAO\n",
    "res_ids['SUB_UP'] = res_ids['SUB_BAS'].apply(lambda x: reservoir_upstream_downstream(x, df_fao_hydro, 'Upstream'))\n",
    "res_ids['SUB_DN'] = res_ids['SUB_BAS'].apply(lambda x: reservoir_upstream_downstream(x, df_fao_hydro, 'Downstream'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-matrix",
   "metadata": {},
   "source": [
    "<h3>COLUMN NAMES</h3>\n",
    "\n",
    "\n",
    "<li>CWC_NAME = Name used by CWC daily water levels data</li>\n",
    "<li>PFAF_ID = Unique watershed identifier for Hydrobasin 6 system (used by Aqueduct) </li>\n",
    "<li>HYBAS_ID = Additional watershed identifier for Hydrobasin 6 system (only used to ID upstream/downstream)  </li>\n",
    "<li>GID_2 = Admin Level 2 ID (one level below states/provinces) </li>\n",
    "<li>MAJ_BAS = FAO Major Basins IDs. These can be matched to basin names </li>\n",
    "<li>SUB_BAS = FAO Sub Basins IDs. These can be matched to basin names  </li>\n",
    "<li>PFAF_UP = PFAF IDs for basins Upstream of reservoir </li>\n",
    "<li>PFAF_DN = PFAF IDs for basins Downstream of reservoir  </li>\n",
    "<li>SUB_UP = FAO Sub Basin IDs for basins Upstream of reservoir  </li>\n",
    "<li>SUB_DN = FAO Sub Basin IDs for basins Downstream of reservoir  </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "great-italy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CWC_NAME</th>\n",
       "      <th>PFAF_ID</th>\n",
       "      <th>HYBAS_ID</th>\n",
       "      <th>GID_2</th>\n",
       "      <th>MAJ_BAS</th>\n",
       "      <th>SUB_BAS</th>\n",
       "      <th>PFAF_UP</th>\n",
       "      <th>PFAF_DN</th>\n",
       "      <th>SUB_UP</th>\n",
       "      <th>SUB_DN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRAND_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>Tilaiya</td>\n",
       "      <td>[453146]</td>\n",
       "      <td>[4060963930.0]</td>\n",
       "      <td>[IND.15.10_1]</td>\n",
       "      <td>[5036]</td>\n",
       "      <td>[36002]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[453141, 453143, 453145]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>Rihand</td>\n",
       "      <td>[452438]</td>\n",
       "      <td>[4060903120.0]</td>\n",
       "      <td>[IND.19.46_1, IND.34.72_1]</td>\n",
       "      <td>[5035]</td>\n",
       "      <td>[35031]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[452100, 452300, 452411, 452413, 452415, 45241...</td>\n",
       "      <td>[35030]</td>\n",
       "      <td>[35029, 35032, 35034, 35046, 35048, 35084]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4862</th>\n",
       "      <td>Maithon</td>\n",
       "      <td>[453146]</td>\n",
       "      <td>[4060963930.0]</td>\n",
       "      <td>[IND.36.3_1, IND.15.11_1, IND.15.4_1]</td>\n",
       "      <td>[5036]</td>\n",
       "      <td>[36002]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[453141, 453143, 453145]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4863</th>\n",
       "      <td>Tenughat</td>\n",
       "      <td>[453149]</td>\n",
       "      <td>[4060961650.0]</td>\n",
       "      <td>[IND.15.20_1, IND.15.1_1]</td>\n",
       "      <td>[5036]</td>\n",
       "      <td>[36002]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[453141, 453143, 453145, 453147]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4865</th>\n",
       "      <td>Panchet</td>\n",
       "      <td>[453147]</td>\n",
       "      <td>[4060964080.0]</td>\n",
       "      <td>[IND.36.18_1, IND.15.4_1]</td>\n",
       "      <td>[5036]</td>\n",
       "      <td>[36002]</td>\n",
       "      <td>[453148, 453149]</td>\n",
       "      <td>[453141, 453143, 453145]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4881</th>\n",
       "      <td>Bargi</td>\n",
       "      <td>[454067]</td>\n",
       "      <td>[4060979850.0]</td>\n",
       "      <td>[IND.19.40_1, IND.19.27_1, IND.19.24_1]</td>\n",
       "      <td>[5048]</td>\n",
       "      <td>[48002]</td>\n",
       "      <td>[454068, 454069]</td>\n",
       "      <td>[454061, 454063, 454065]</td>\n",
       "      <td>[48001]</td>\n",
       "      <td>[48004, 48005, 48006, 48007, 48008, 48009, 480...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>Hirakud</td>\n",
       "      <td>[453230, 453250, 453240]</td>\n",
       "      <td>[4061031590.0, 4061017990.0, 4061017890.0]</td>\n",
       "      <td>[IND.26.4_1, IND.26.28_1, IND.26.14_1]</td>\n",
       "      <td>[5038, 5038, 5038]</td>\n",
       "      <td>[38005, 38006, 38007]</td>\n",
       "      <td>[453240, 453250, 453260, 453270, 453280, 45329...</td>\n",
       "      <td>[453210, 453230]</td>\n",
       "      <td>[38001, 38002, 38003, 38004, 38005, 38006]</td>\n",
       "      <td>[38007, 38011, 38012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>Sriramsagar</td>\n",
       "      <td>[453479, 453477, 453478]</td>\n",
       "      <td>[4061060950.0, 4061061290.0, 4061060870.0]</td>\n",
       "      <td>[IND.32.8_1, IND.32.1_1]</td>\n",
       "      <td>[5040]</td>\n",
       "      <td>[40010]</td>\n",
       "      <td>[453478, 453479, 453481, 453482, 453483, 45348...</td>\n",
       "      <td>[453410, 453430, 453450, 453471, 453473, 45347...</td>\n",
       "      <td>[40001, 40002, 40003, 40004, 40005, 40006, 400...</td>\n",
       "      <td>[40013, 40020, 40023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>Mettur</td>\n",
       "      <td>[453805]</td>\n",
       "      <td>[4061145690.0]</td>\n",
       "      <td>[IND.31.18_1, IND.31.5_1, IND.16.8_1]</td>\n",
       "      <td>[5044]</td>\n",
       "      <td>[44005]</td>\n",
       "      <td>[453806, 453807, 453808, 453809]</td>\n",
       "      <td>[453801, 453803]</td>\n",
       "      <td>[44001, 44002, 44003, 44004]</td>\n",
       "      <td>[44007]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6992</th>\n",
       "      <td>indirasagar</td>\n",
       "      <td>[454062, 454061, 454063]</td>\n",
       "      <td>[4061001610.0, 4060031610.0, 4061001460.0]</td>\n",
       "      <td>[IND.19.18_1, IND.19.21_1, IND.19.15_1]</td>\n",
       "      <td>[5048, 5048, 5048]</td>\n",
       "      <td>[48011, 48009, 48010]</td>\n",
       "      <td>[454062, 454063, 454064, 454065, 454066, 45406...</td>\n",
       "      <td>[454061]</td>\n",
       "      <td>[48001, 48002, 48003, 48004, 48005, 48006, 480...</td>\n",
       "      <td>[48011, 48013, 48015, 48016, 48017]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pench</td>\n",
       "      <td>[453464]</td>\n",
       "      <td>[4061051450.0]</td>\n",
       "      <td>[IND.20.19_1]</td>\n",
       "      <td>[5040]</td>\n",
       "      <td>[40017]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[453410, 453430, 453450, 453461, 453463]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[40010, 40013, 40014, 40015, 40016, 40020, 40023]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CWC_NAME                   PFAF_ID  \\\n",
       "GRAND_ID                                          \n",
       "4857          Tilaiya                  [453146]   \n",
       "4858           Rihand                  [452438]   \n",
       "4862          Maithon                  [453146]   \n",
       "4863         Tenughat                  [453149]   \n",
       "4865          Panchet                  [453147]   \n",
       "4881            Bargi                  [454067]   \n",
       "4898          Hirakud  [453230, 453250, 453240]   \n",
       "4946      Sriramsagar  [453479, 453477, 453478]   \n",
       "5014           Mettur                  [453805]   \n",
       "6992      indirasagar  [454062, 454061, 454063]   \n",
       "0               Pench                  [453464]   \n",
       "\n",
       "                                            HYBAS_ID  \\\n",
       "GRAND_ID                                               \n",
       "4857                                  [4060963930.0]   \n",
       "4858                                  [4060903120.0]   \n",
       "4862                                  [4060963930.0]   \n",
       "4863                                  [4060961650.0]   \n",
       "4865                                  [4060964080.0]   \n",
       "4881                                  [4060979850.0]   \n",
       "4898      [4061031590.0, 4061017990.0, 4061017890.0]   \n",
       "4946      [4061060950.0, 4061061290.0, 4061060870.0]   \n",
       "5014                                  [4061145690.0]   \n",
       "6992      [4061001610.0, 4060031610.0, 4061001460.0]   \n",
       "0                                     [4061051450.0]   \n",
       "\n",
       "                                            GID_2             MAJ_BAS  \\\n",
       "GRAND_ID                                                                \n",
       "4857                                [IND.15.10_1]              [5036]   \n",
       "4858                   [IND.19.46_1, IND.34.72_1]              [5035]   \n",
       "4862        [IND.36.3_1, IND.15.11_1, IND.15.4_1]              [5036]   \n",
       "4863                    [IND.15.20_1, IND.15.1_1]              [5036]   \n",
       "4865                    [IND.36.18_1, IND.15.4_1]              [5036]   \n",
       "4881      [IND.19.40_1, IND.19.27_1, IND.19.24_1]              [5048]   \n",
       "4898       [IND.26.4_1, IND.26.28_1, IND.26.14_1]  [5038, 5038, 5038]   \n",
       "4946                     [IND.32.8_1, IND.32.1_1]              [5040]   \n",
       "5014        [IND.31.18_1, IND.31.5_1, IND.16.8_1]              [5044]   \n",
       "6992      [IND.19.18_1, IND.19.21_1, IND.19.15_1]  [5048, 5048, 5048]   \n",
       "0                                   [IND.20.19_1]              [5040]   \n",
       "\n",
       "                        SUB_BAS  \\\n",
       "GRAND_ID                          \n",
       "4857                    [36002]   \n",
       "4858                    [35031]   \n",
       "4862                    [36002]   \n",
       "4863                    [36002]   \n",
       "4865                    [36002]   \n",
       "4881                    [48002]   \n",
       "4898      [38005, 38006, 38007]   \n",
       "4946                    [40010]   \n",
       "5014                    [44005]   \n",
       "6992      [48011, 48009, 48010]   \n",
       "0                       [40017]   \n",
       "\n",
       "                                                    PFAF_UP  \\\n",
       "GRAND_ID                                                      \n",
       "4857                                                     []   \n",
       "4858                                                     []   \n",
       "4862                                                     []   \n",
       "4863                                                     []   \n",
       "4865                                       [453148, 453149]   \n",
       "4881                                       [454068, 454069]   \n",
       "4898      [453240, 453250, 453260, 453270, 453280, 45329...   \n",
       "4946      [453478, 453479, 453481, 453482, 453483, 45348...   \n",
       "5014                       [453806, 453807, 453808, 453809]   \n",
       "6992      [454062, 454063, 454064, 454065, 454066, 45406...   \n",
       "0                                                        []   \n",
       "\n",
       "                                                    PFAF_DN  \\\n",
       "GRAND_ID                                                      \n",
       "4857                               [453141, 453143, 453145]   \n",
       "4858      [452100, 452300, 452411, 452413, 452415, 45241...   \n",
       "4862                               [453141, 453143, 453145]   \n",
       "4863                       [453141, 453143, 453145, 453147]   \n",
       "4865                               [453141, 453143, 453145]   \n",
       "4881                               [454061, 454063, 454065]   \n",
       "4898                                       [453210, 453230]   \n",
       "4946      [453410, 453430, 453450, 453471, 453473, 45347...   \n",
       "5014                                       [453801, 453803]   \n",
       "6992                                               [454061]   \n",
       "0                  [453410, 453430, 453450, 453461, 453463]   \n",
       "\n",
       "                                                     SUB_UP  \\\n",
       "GRAND_ID                                                      \n",
       "4857                                                     []   \n",
       "4858                                                [35030]   \n",
       "4862                                                     []   \n",
       "4863                                                     []   \n",
       "4865                                                     []   \n",
       "4881                                                [48001]   \n",
       "4898             [38001, 38002, 38003, 38004, 38005, 38006]   \n",
       "4946      [40001, 40002, 40003, 40004, 40005, 40006, 400...   \n",
       "5014                           [44001, 44002, 44003, 44004]   \n",
       "6992      [48001, 48002, 48003, 48004, 48005, 48006, 480...   \n",
       "0                                                        []   \n",
       "\n",
       "                                                     SUB_DN  \n",
       "GRAND_ID                                                     \n",
       "4857                                                     []  \n",
       "4858             [35029, 35032, 35034, 35046, 35048, 35084]  \n",
       "4862                                                     []  \n",
       "4863                                                     []  \n",
       "4865                                                     []  \n",
       "4881      [48004, 48005, 48006, 48007, 48008, 48009, 480...  \n",
       "4898                                  [38007, 38011, 38012]  \n",
       "4946                                  [40013, 40020, 40023]  \n",
       "5014                                                [44007]  \n",
       "6992                    [48011, 48013, 48015, 48016, 48017]  \n",
       "0         [40010, 40013, 40014, 40015, 40016, 40020, 40023]  "
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ids.to_csv(res_ids_path)\n",
    "res_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-ukraine",
   "metadata": {},
   "source": [
    "# TO COME: Match Powerplants to reservoirs. Confirm link using Vasudha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "understood-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = gpd.read_file(context_gdb, layer='PowerPlant')\n",
    "pp_bas = gpd.sjoin(pp, fao, how=\"left\", op='intersects') # Join shapefile to reservoir shapefile\n",
    "pp_bas =pp_bas.filter(['name', 'gppd_indr', 'SUB_BAS', 'MAJ_BAS'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
